apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: redis-mps-sharq
  namespace: messaging
  annotations:
    redis.plivo.com/bandwidth: 0
    redis.plivo.com/userMemory: 5000mb
    redis.plivo.com/throughput: 0
    filepath: clusters/pre-prod/pre-prod-us-east-1/tenants/messaging/messaging-common/resources/redis-mps-sharq.yaml
spec:
  releaseName: redis-mps-sharq
  interval: 1m0s
  timeout: 10m
  install:
    remediation:
      retries: 3
    disableWait: true
  upgrade:
    disableWait: true
  chart:
    spec:
      chart: redis-sentinel
      version: 20.1.5
      sourceRef:
        kind: GitRepository
        name: devops-helm-charts
        namespace: flux-system
  values:
    global:
      security:
        allowInsecureImages: true
    image:
      registry: 857556598075.dkr.ecr.us-west-1.amazonaws.com
      repository: plivo/bitnami-redis/redis-7.4.0
      tag: 25.02.28.1484
    auth:
      enabled: false
      sentinel: false
    metrics:
      enabled: true
      image:
        registry: 857556598075.dkr.ecr.us-west-1.amazonaws.com
        repository: plivo/bitnami-redis/redis-exporter-1.63.0
        tag: 25.02.26.1481
      resources:
        limits:
          ephemeral-storage: 2Gi
          memory: 20Mi
        requests:
          ephemeral-storage: 50Mi
          memory: 20Mi
    architecture: replication
    useHostnames: true
    commonConfiguration: |-
      bind 0.0.0.0
      maxmemory 5000mb
      maxmemory-policy noeviction
      # Enable AOF https://redis.io/topics/persistence#append-only-file
      appendonly yes
      save 900 1
      save 300 10
      save 60 10000
    replica:
      extraFlags:
        - '--loadmodule /opt/bitnami/redis/modules/redisjson.so'
      persistence:
        enabled: true
        storageClass: gp3
        size: 15Gi
      resources:
        requests:
          memory: 5040Mi
        limits:
          memory: 5040Mi
      replicaCount: 2
      tolerations:
        - key: ops.plivo.com/dedicated-for
          value: messaging
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - topologyKey: kubernetes.io/hostname
              labelSelector:
                matchExpressions:
                  - key: app.kubernetes.io/name
                    operator: In
                    values:
                      - redis-mps-sharq
      lifecycleHooks:
        postStart:
          exec:
            command:
              - /bin/bash
              - '-c'
              - |-
                nohup /bin/bash -c '(
                LOG_FILE=/tmp/poststart.err

                echo "Waiting for Redis to be ready..."
                until redis-cli ping | grep PONG; do 
                  sleep 1
                done

                echo "Loading Lua scripts efficiently..."

                for script in /luascripts/*.lua; do
                  [ -f "$script" ] || continue
                  echo "Processing $(basename "$script")..."

                  SHA=$(cat "$script" | xargs -0 redis-cli --raw SCRIPT LOAD 2>>$LOG_FILE)
                  if [ -z "$SHA" ]; then
                    echo "Error loading script: $(basename "$script")"
                    exit 1
                  fi

                  echo "$(basename "$script"): $SHA"
                done

                # Mark readiness for probe
                echo "All scripts loaded successfully."
                touch /tmp/scripts-loaded
                )' >/tmp/poststart.out 2>&1 & disown
      customReadinessProbe:
        exec:
          command:
            - sh
            - '-c'
            - |-
              if [ -f /tmp/scripts-loaded ]; then
                exec /health/ping_readiness_local.sh 1
              else
                exit 1
              fi
        initialDelaySeconds: 20
        timeoutSeconds: 1
        periodSeconds: 5
        successThreshold: 1
        failureThreshold: 5
      extraVolumes:
        - name: lua-scripts
          configMap:
            name: lua-redis-mps-sharq
      extraVolumeMounts:
        - name: lua-scripts
          mountPath: /luascripts
    sentinel:
      image:
        registry: 857556598075.dkr.ecr.us-west-1.amazonaws.com
        repository: plivo/bitnami-redis/redis-sentinel-7.4.0
        tag: 25.02.26.1480
      enabled: true
      quorum: 2
      configuration: |
        sentinel down-after-milliseconds master 1000
      resources:
        requests:
          memory: 20Mi
        limits:
          memory: 20Mi
      masterSet: master
    networkPolicy:
      enabled: true
      allowExternal: false
      allowExternalEgress: false
      extraIngress:
        - from:
            - podSelector:
                matchLabels:
                  app.kubernetes.io/instance: common-haproxy-redis
                  app.kubernetes.io/name: haproxy
          ports:
            - port: 6379
              protocol: TCP
        - from:
            - podSelector:
                matchLabels:
                  app: redis-extra-sentinel-mps-sharq
          ports:
            - port: 26379
              protocol: TCP
            - port: 6379
              protocol: TCP
      extraEgress:
        - to:
            - podSelector:
                matchLabels:
                  app: redis-extra-sentinel-mps-sharq
          ports:
            - port: 6379
              protocol: TCP
            - port: 26379
              protocol: TCP
      ingressNSMatchLabels: {}
      ingressNSPodMatchLabels: {}
      metrics:
        allowExternal: false
        ingressNSMatchLabels:
          kubernetes.io/metadata.name: monitoring
        ingressNSPodMatchLabels: {}

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-extra-sentinel-mps-sharq
  namespace: messaging
  labels:
    app: redis-extra-sentinel-mps-sharq
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis-extra-sentinel-mps-sharq
  template:
    metadata:
      labels:
        app: redis-extra-sentinel-mps-sharq
    spec:
      tolerations:
        - key: ops.plivo.com/dedicated-for
          value: messaging-redis-sentinel-spot
      containers:
        - name: sentinel
          image: 857556598075.dkr.ecr.us-west-1.amazonaws.com/plivo/bitnami-redis/redis-sentinel-7.4.0:25.02.26.1480
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
            limits:
              cpu: 100m
              memory: 100Mi
          ports:
            - name: sentinel
              containerPort: 26379
          env:
            - name: REDIS_MASTER_SET
              value: master
            - name: REDIS_MASTER_HOST
              value: redis-mps-sharq-node-0.redis-mps-sharq-headless.messaging.svc.cluster.local
            - name: REDIS_MASTER_PORT_NUMBER
              value: '6379'
            - name: REDIS_SENTINEL_QUORUM
              value: '2'
            - name: REDIS_SENTINEL_DOWN_AFTER_MILLISECONDS
              value: '1000'
            - name: REDIS_SENTINEL_FAILOVER_TIMEOUT
              value: '180000'
            - name: REDIS_SENTINEL_RESOLVE_HOSTNAMES
              value: 'yes'
          readinessProbe:
            exec:
              command:
                - bash
                - '-lc'
                - /opt/bitnami/redis-sentinel/bin/redis-cli -p 26379 ping | grep PONG
            initialDelaySeconds: 5
            periodSeconds: 5

---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: redis-extra-sentinel-mps-sharq-isolation
  namespace: messaging
spec:
  podSelector:
    matchLabels:
      app: redis-extra-sentinel-mps-sharq
  policyTypes:
    - Ingress
    - Egress
  ingress:
    - from:
        - podSelector:
            matchLabels:
              app.kubernetes.io/instance: redis-mps-sharq
              app.kubernetes.io/name: redis
      ports:
        - protocol: TCP
          port: 26379
        - protocol: TCP
          port: 6379
  egress:
    - to:
        - namespaceSelector: {}
      ports:
        - protocol: UDP
          port: 53
        - protocol: TCP
          port: 53
    - to:
        - podSelector:
            matchLabels:
              app.kubernetes.io/instance: redis-mps-sharq
              app.kubernetes.io/name: redis
      ports:
        - protocol: TCP
          port: 6379
        - protocol: TCP
          port: 26379

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: lua-redis-mps-sharq
  namespace: messaging
data:
  dequeue.lua.lua: "-- script to dequeue a job from sharq.\n\n-- input:\n--     KEYS[1] - <key_prefix>\n--     KEYS[2] - <queue_type>\n--\n--     ARGV[1] - <current_timestamp>\n--     ARGV[2] - <job_expiry_interval>\n-- output:\n--     { queue_id, job_id, payload, requeues_remaining }\n\n\nlocal prefix = KEYS[1]\nlocal queue_type = KEYS[2]\n\nlocal current_timestamp = ARGV[1]\nlocal job_expiry_interval = ARGV[2]\n\n\nlocal ready_queue_id_list = redis.call('ZRANGEBYSCORE', prefix .. ':' .. queue_type, 0, current_timestamp)\nif next(ready_queue_id_list) ~= nil then\n   -- there is a queue ready to be dequeued.\n   local ready_queue_id = ready_queue_id_list[1]\n   -- dequeue a job from the job queue.\n   local job_id = redis.call('LPOP', prefix .. ':' .. queue_type .. ':' .. ready_queue_id)\n   -- get the payload for this job\n   local payload = redis.call('HGET', prefix .. ':payload', queue_type .. ':' .. ready_queue_id .. ':' .. job_id)\n   -- update the time keeper with the current dequeue time.\n   redis.call('PSETEX', prefix .. ':' .. queue_type .. ':' .. ready_queue_id .. ':time', job_expiry_interval, current_timestamp)\n   -- check if there are any more jobs of this queue in the job queue.\n   if redis.call('LLEN', prefix .. ':' .. queue_type .. ':' .. ready_queue_id) == 0 then\n      -- there are no more jobs of this queue. remove this queue from the ready sorted set.\n      redis.call('ZREM', prefix .. ':' .. queue_type, ready_queue_id)\n      -- now check if the ready sorted set is empty.\n      if redis.call('EXISTS', prefix .. ':' .. queue_type) ~= 1 then\n\t -- the ready sorted set is empty. remove this 'queue_type' from\n\t -- the metris ready queue type set\n\t redis.call('SREM', prefix .. ':ready:queue_type', queue_type)\n      end\n   else\n      -- there are more jobs in the queue. update the next\n      -- dequeue time for this queue in the ready sorted set.\n      local next_dequeue_time = current_timestamp\n      local interval = tonumber(redis.call('HGET', prefix .. ':interval', queue_type .. ':' .. ready_queue_id))\n      if interval then\n\t next_dequeue_time = current_timestamp + interval\n      end\n      redis.call('ZADD', prefix .. ':' .. queue_type, next_dequeue_time, ready_queue_id)\n   end\n   local job_expiry_time = current_timestamp + job_expiry_interval\n   -- finally, add the job_id and queue_id that was dequeued into the active sorted set.\n   redis.call('ZADD', prefix .. ':' .. queue_type .. ':active', job_expiry_time, ready_queue_id .. ':' .. job_id)\n   -- add the queue_type to metrics active queue type set.\n   redis.call('SADD', prefix .. ':active:queue_type', queue_type)\n\n   -- get the requeues_remaining for this job\n   local requeues_remaining = redis.call('HGET', prefix .. ':' .. queue_type .. ':' .. ready_queue_id .. ':requeues_remaining', job_id)\n\n   -- update the metrics counters\n   -- update global counter.\n   local timestamp_minute = math.floor(current_timestamp/60000) * 60000 -- get the epoch for the minute\n   local expiry_time = math.floor((timestamp_minute + 600000) / 1000) -- store the data for 10 minutes.\n   if redis.call('EXISTS', prefix .. ':dequeue_counter:' .. timestamp_minute) ~= 1 then\n      -- counter does not exists. set the initial value and expiry.\n      redis.call('SET', prefix .. ':dequeue_counter:' .. timestamp_minute, 1)\n      redis.call('EXPIREAT', prefix .. ':dequeue_counter:' .. timestamp_minute, expiry_time)\n   else\n      -- counter already exists. just increment the value.\n      redis.call('INCR', prefix .. ':dequeue_counter:' .. timestamp_minute)\n   end\n\n   -- update the current queue counter.\n   if redis.call('EXISTS', prefix .. ':' .. queue_type .. ':' .. ready_queue_id .. ':dequeue_counter:' .. timestamp_minute) ~= 1 then\n      -- counter does not exists. set the initial value and expiry.\n      redis.call('SET', prefix .. ':' .. queue_type .. ':' .. ready_queue_id .. ':dequeue_counter:' .. timestamp_minute, 1)\n      redis.call('EXPIREAT', prefix .. ':' .. queue_type .. ':' .. ready_queue_id .. ':dequeue_counter:' .. timestamp_minute, expiry_time)\n   else\n      -- counter already exists. just increment the value.\n      redis.call('INCR', prefix .. ':' .. queue_type .. ':' .. ready_queue_id .. ':dequeue_counter:' .. timestamp_minute)\n   end\n\n   return { ready_queue_id, job_id, payload, requeues_remaining }\nelse\n   return { }\nend"
  enqueue.lua.lua: |-
    -- script to enqueue a job into sharq.

    -- input:
    --     KEYS[1] - <key_prefix>
    --     KEYS[2] - <queue_type>
    --
    --     ARGV[1] - <current_timestamp>
    --     ARGV[2] - <queue_id>
    --     ARGV[3] - <job_id>
    --     ARGV[4] - <serialized_payload>
    --     ARGV[5] - <interval>
    --     ARGV[6] - <requeue_limit>
    -- output:
    --     nil

    local prefix = KEYS[1]
    local queue_type = KEYS[2]

    local current_timestamp = ARGV[1]
    local queue_id = ARGV[2]
    local job_id = ARGV[3]
    local payload = ARGV[4]
    local interval = ARGV[5]
    local requeue_limit = ARGV[6]

    -- push the job id into the job queue.
    redis.call('RPUSH', prefix .. ':' .. queue_type .. ':' .. queue_id, job_id)

    -- update the payload map.
    redis.call('HSET', prefix .. ':payload', queue_type .. ':' .. queue_id .. ':' .. job_id, payload)

    -- update the interval map.
    redis.call('HSET', prefix .. ':interval', queue_type .. ':' .. queue_id, interval)

    -- update the requeue limit map.
    redis.call('HSET', prefix .. ':' .. queue_type .. ':' .. queue_id .. ':requeues_remaining', job_id, requeue_limit)

    -- check if the queue of this job is already present in the ready sorted set.
    if not redis.call('ZRANK', prefix .. ':' .. queue_type, queue_id) then
       -- the ready sorted set is empty, update it and add it to metrics ready queue type set.
       redis.call('SADD', prefix .. ':ready:queue_type', queue_type)
       if redis.call('EXISTS', prefix .. ':' .. queue_type .. ':' .. queue_id .. ':time') ~= 1 then
          -- time keeper does not exist
          -- update the ready sorted set with current time as ready time.
          redis.call('ZADD', prefix .. ':' .. queue_type, current_timestamp, queue_id)
       else
          -- time keeper exists
          local last_dequeue_time = redis.call('GET', prefix .. ':' .. queue_type .. ':' .. queue_id .. ':time')
          local ready_time = interval + last_dequeue_time
          redis.call('ZADD', prefix .. ':' .. queue_type, ready_time, queue_id)
       end
    end

    -- update the metrics counters
    -- update global counter.
    local timestamp_minute = math.floor(current_timestamp/60000) * 60000 -- get the epoch for the minute
    local expiry_time = math.floor((timestamp_minute + 600000) / 1000) -- store the data for 10 minutes.
    if redis.call('EXISTS', prefix .. ':enqueue_counter:' .. timestamp_minute) ~= 1 then
       -- counter does not exists. set the initial value and expiry.
       redis.call('SET', prefix .. ':enqueue_counter:' .. timestamp_minute, 1)
       redis.call('EXPIREAT', prefix .. ':enqueue_counter:' .. timestamp_minute, expiry_time)
    else
       -- counter already exists. just increment the value.
       redis.call('INCR', prefix .. ':enqueue_counter:' .. timestamp_minute)
    end

    -- update the current queue counter.
    if redis.call('EXISTS', prefix .. ':' .. queue_type .. ':' .. queue_id .. ':enqueue_counter:' .. timestamp_minute) ~= 1 then
       -- counter does not exists. set the initial value and expiry.
       redis.call('SET', prefix .. ':' .. queue_type .. ':' .. queue_id .. ':enqueue_counter:' .. timestamp_minute, 1)
       redis.call('EXPIREAT', prefix .. ':' .. queue_type .. ':' .. queue_id .. ':enqueue_counter:' .. timestamp_minute, expiry_time)
    else
       -- counter already exists. just increment the value.
       redis.call('INCR', prefix .. ':' .. queue_type .. ':' .. queue_id .. ':enqueue_counter:' .. timestamp_minute)
    end
  finish.lua.lua: |-
    -- script to mark a job as completed (finished) successfully.

    -- input:
    --     KEYS[1] - <key_prefix>
    --     KEYS[2] - <queue_type>
    --
    --     ARGV[1] - <queue_id>
    --     ARGV[2] - <job_id>
    -- output:
    --     nil

    local prefix = KEYS[1]
    local queue_type = KEYS[2]
    local queue_id = ARGV[1]
    local job_id = ARGV[2]


    -- remove the job from active sorted set.
    local response = redis.call('ZREM', prefix .. ':' .. queue_type .. ':active', queue_id .. ':' .. job_id)
    if response ~= 1 then
       -- the job was not found in the active sorted set. Non existent job or
       -- the job is expired and was requeued back.
       return 0
    end

    -- check if the just-removed job was the last job in the active sorted set.
    if redis.call('EXISTS', prefix .. ':' .. queue_type .. ':active') ~= 1 then
       -- yes. this was the last job. remove this queue_type
       -- from the metrics active queue type set.
       redis.call('SREM', prefix .. ':active:queue_type', queue_type)
    end
    -- delete the payload related to this job from the payload map.
    redis.call('HDEL', prefix .. ':payload', queue_type .. ':' .. queue_id .. ':' .. job_id)
    if redis.call('EXISTS', prefix .. ':' .. queue_type .. ':' .. queue_id) ~= 1 then
       -- there are no more jobs in this queue. we can safely delete the interval.
       redis.call('HDEL', prefix .. ':interval', queue_type .. ':' .. queue_id)
    end

    -- delete the requeues_remaining entry for this job.
    redis.call('HDEL', prefix .. ':' .. queue_type .. ':' .. queue_id .. ':requeues_remaining', job_id)

    return 1
  interval.lua.lua: |-
    -- script to update the interval for a queue only if it exists.

    -- input:
    --     KEYS[1] - <hashmap_key>
    --     KEYS[2] - <queue_key>
    --
    --     ARGV[1] - <interval>

    if redis.call('HEXISTS', KEYS[1], KEYS[2]) ~= 1 then
       -- interval does not exist
       return 0
    else
       -- interval exists. update the time.
       redis.call('HSET', KEYS[1], KEYS[2], ARGV[1])
       return 1
    end
  metrics.lua.lua: |-
    -- script to return a sliding window of rates over the past 10 mins.

    -- input:
    --     KEYS[1] - <key_prefix>
    --
    --     ARGV[1] - <current_timestamp>
    -- output:
    --     { enqueue_response, dequeue_response }

    local enqueue_response = {}
    local dequeue_response = {}
    local timestamp_minute = math.floor(ARGV[1]/60000) * 60000 -- get the epoch for the minute
    for i=0, 9 do
       local enqueue_counter_value = redis.call('GET', KEYS[1] .. ':enqueue_counter:' .. timestamp_minute)
       local dequeue_counter_value = redis.call('GET', KEYS[1] .. ':dequeue_counter:' .. timestamp_minute)
       table.insert(enqueue_response, timestamp_minute)
       table.insert(enqueue_response, enqueue_counter_value)
       table.insert(dequeue_response, timestamp_minute)
       table.insert(dequeue_response, dequeue_counter_value)
       timestamp_minute = timestamp_minute - 60000
    end

    return { enqueue_response, dequeue_response }
  requeue.lua.lua: "-- script to requeue expired jobs.\n\n-- input:\n--     KEYS[1] - <key_prefix>\n--     KEYS[2] - <queue_type>\n--\n--     ARGV[1] - <current_timestamp>\n--\n-- output:\n--     {} or job_discard_list\n\nlocal prefix = KEYS[1]\nlocal queue_type = KEYS[2]\nlocal current_timestamp = ARGV[1]\n\n-- check if any of the jobs need to be retried\nlocal requeue_job_list = redis.call('ZRANGEBYSCORE', prefix .. ':' .. queue_type .. ':active', 0, current_timestamp)\nlocal job_discard_list = {}\n-- iterate over each job and requeue it.\nfor _, job in pairs(requeue_job_list) do\n   local requeue = true\n   local queue_id, job_id = job:match(\"([^,]+):([^,]+)\")\n   -- check if the job has any pending requeues.\n   local requeues_remaining = redis.call('HGET', prefix .. ':' .. queue_type .. ':' .. queue_id .. ':requeues_remaining', job_id)\n   if requeues_remaining and tonumber(requeues_remaining) > -1 then\n      -- finite requeues_remaining. decrement by one and check.\n      requeues_remaining = requeues_remaining - 1\n      -- update the new requeues_remaining value.\n      redis.call('HSET', prefix .. ':' .. queue_type .. ':' .. queue_id .. ':requeues_remaining', job_id, requeues_remaining)\n      if requeues_remaining == -1 then\n         -- discard this job\n\t table.insert(job_discard_list, job)\n         -- using these flags as Lua doesn't support 'continue'\n\t requeue = false\n      end\n   end\n   if requeue == true then\n       -- enqueue the job at the front of the job queue\n       local job_queue_key = prefix .. ':' .. queue_type .. ':' .. queue_id\n       redis.call('LPUSH', job_queue_key, job_id)\n       -- check if this is the only job in the job queue\n       if redis.call('LLEN', job_queue_key) == 1 then\n\t  -- default when time keeper does not exist. next ready time is now.\n\t  local next_ready_time = current_timestamp\n\t  -- check if the time keeper exists\n\t  if redis.call('EXISTS', prefix .. ':' .. queue_type .. ':' .. queue_id .. ':time') == 1 then\n\t     local last_dequeue_time = tonumber(redis.call('GET', prefix .. ':' .. queue_type .. ':' .. queue_id .. ':time'))\n\t     local interval = tonumber(redis.call('HGET', prefix .. ':interval', queue_type .. ':' .. queue_id))\n\t     -- compute next ready time\n\t     if last_dequeue_time and interval then\n\t\tnext_ready_time = last_dequeue_time + interval\n\t     end\n\t  end\n\t  -- insert this queue into the ready sorted set.\n\t  redis.call('ZADD', prefix .. ':' .. queue_type, next_ready_time, queue_id)\n\t  redis.call('SADD', prefix .. ':ready:queue_type', queue_type)\n       end\n       -- remove this queue_id & job_id from active sorted set.\n       redis.call('ZREM', prefix .. ':' .. queue_type .. ':active', queue_id .. ':' .. job_id)\n       -- check if the removed queue_id was the last item in this active set.\n       if redis.call('EXISTS', prefix .. ':' .. queue_type .. ':active') ~= 1 then\n\t  -- the active set does not exist. remove it from the metrics active queue type set.\n\t  redis.call('SREM', prefix .. ':active:queue_type', queue_type)\n       end\n   end\nend\n\nreturn job_discard_list"
  dequeue-mms.lua.lua: "\n-- script to dequeue a job from sharq.\n-- input:\n--     KEYS[1] - <key_prefix>\n--     KEYS[2] - <queue_type>\n--\n--     ARGV[1] - <current_timestamp>\n--     ARGV[2] - <job_expiry_interval>\n-- output:\n--     { queue_id, job_id, payload, requeues_remaining }\nlocal ready_queue_id_list = redis.call('ZRANGEBYSCORE', KEYS[1] .. ':' .. KEYS[2], 0, ARGV[1])\nif next(ready_queue_id_list) ~= nil then\n   -- there is a queue ready to be dequeued.\n   local ready_queue_id = ready_queue_id_list[1]\n   -- dequeue a job from the job queue.\n   local job_id = redis.call('LPOP', KEYS[1] .. ':' .. KEYS[2] .. ':' .. ready_queue_id)\n   -- get the payload for this job\n   local payload = redis.call('HGET', KEYS[1] .. ':payload', KEYS[2] .. ':' .. ready_queue_id .. ':' .. job_id)\n   -- update the time keeper with the current dequeue time.\n   local interval = redis.call('HGET', KEYS[1] .. ':interval', KEYS[2] .. ':' .. ready_queue_id)\n   redis.call('PSETEX', KEYS[1] .. ':' .. KEYS[2] .. ':' .. ready_queue_id .. ':time', ARGV[2], ARGV[1])\n   -- check if there are any more jobs of this queue in the job queue.\n   if redis.call('LLEN', KEYS[1] .. ':' .. KEYS[2] .. ':' .. ready_queue_id) == 0 then\n      -- there are no more jobs of this queue. remove this queue from the ready sorted set.\n      redis.call('ZREM', KEYS[1] .. ':' .. KEYS[2], ready_queue_id)\n      -- now check if the ready sorted set is empty.\n      if redis.call('EXISTS', KEYS[1] .. ':' .. KEYS[2]) ~= 1 then\n\t -- the ready sorted set is empty. remove this 'queue_type' from\n\t -- the metris ready queue type set\n\t redis.call('SREM', KEYS[1] .. ':ready:queue_type', KEYS[2])\n      end\n   else\n      -- there are more jobs in the queue. update the next\n      -- dequeue time for this queue in the ready sorted set.\n      local next_dequeue_time = ARGV[1] + interval\n      redis.call('ZADD', KEYS[1] .. ':' .. KEYS[2], next_dequeue_time, ready_queue_id)\n   end\n   local job_expiry_time = ARGV[1] + ARGV[2]\n   -- finally, add the job_id and queue_id that was dequeued into the active sorted set.\n   redis.call('ZADD', KEYS[1] .. ':' .. KEYS[2] .. ':active', job_expiry_time, ready_queue_id .. ':' .. job_id)\n   -- add the queue_type to metrics active queue type set.\n   redis.call('SADD', KEYS[1] .. ':active:queue_type', KEYS[2])\n   -- get the requeues_remaining for this job\n   local requeues_remaining = redis.call('HGET', KEYS[1] .. ':' .. KEYS[2] .. ':' .. ready_queue_id .. ':requeues_remaining', job_id)\n   -- update the metrics counters\n   -- update global counter.\n   local timestamp_minute = math.floor(ARGV[1]/60000) * 60000 -- get the epoch for the minute\n   local expiry_time = math.floor((timestamp_minute + 600000) / 1000) -- store the data for 10 minutes.\n   if redis.call('EXISTS', KEYS[1] .. ':dequeue_counter:' .. timestamp_minute) ~= 1 then\n      -- counter does not exists. set the initial value and expiry.\n      redis.call('SET', KEYS[1] .. ':dequeue_counter:' .. timestamp_minute, 1)\n      redis.call('EXPIREAT', KEYS[1] .. ':dequeue_counter:' .. timestamp_minute, expiry_time)\n   else\n      -- counter already exists. just increment the value.\n      redis.call('INCR', KEYS[1] .. ':dequeue_counter:' .. timestamp_minute)\n   end\n   -- update the current queue counter.\n   if redis.call('EXISTS', KEYS[1] .. ':' .. KEYS[2] .. ':' .. ready_queue_id .. ':dequeue_counter:' .. timestamp_minute) ~= 1 then\n      -- counter does not exists. set the initial value and expiry.\n      redis.call('SET', KEYS[1] .. ':' .. KEYS[2] .. ':' .. ready_queue_id .. ':dequeue_counter:' .. timestamp_minute, 1)\n      redis.call('EXPIREAT', KEYS[1] .. ':' .. KEYS[2] .. ':' .. ready_queue_id .. ':dequeue_counter:' .. timestamp_minute, expiry_time)\n   else\n      -- counter already exists. just increment the value.\n      redis.call('INCR', KEYS[1] .. ':' .. KEYS[2] .. ':' .. ready_queue_id .. ':dequeue_counter:' .. timestamp_minute)\n   end\n   return { ready_queue_id, job_id, payload, requeues_remaining }\nelse\n   return { }\nend\n"
  enqueue-mms.lua.lua: |

    -- script to enqueue a job into sharq.

    -- input:
    --     KEYS[1] - <key_prefix>
    --     KEYS[2] - <queue_type>
    --
    --     ARGV[1] - <current_timestamp>
    --     ARGV[2] - <queue_id>
    --     ARGV[3] - <job_id>
    --     ARGV[4] - <serialized_payload>
    --     ARGV[5] - <interval>
    --     ARGV[6] - <requeue_limit>
    -- output:
    --     nil


    -- push the job id into the job queue.
    redis.call('RPUSH', KEYS[1] .. ':' .. KEYS[2] .. ':' .. ARGV[2], ARGV[3])

    -- update the payload map.
    redis.call('HSET', KEYS[1] .. ':payload', KEYS[2] .. ':' .. ARGV[2] .. ':' .. ARGV[3], ARGV[4])

    -- update the interval map.
    redis.call('HSET', KEYS[1] .. ':interval', KEYS[2] .. ':' .. ARGV[2], ARGV[5])

    -- update the requeue limit map.
    redis.call('HSET', KEYS[1] .. ':' .. KEYS[2] .. ':' .. ARGV[2] .. ':requeues_remaining', ARGV[3], ARGV[6])

    -- check if the queue of this job is already present in the ready sorted set.
    if not redis.call('ZRANK', KEYS[1] .. ':' .. KEYS[2], ARGV[2]) then
       -- the ready sorted set is empty, update it and add it to metrics ready queue type set.
       redis.call('SADD', KEYS[1] .. ':ready:queue_type', KEYS[2])
       if redis.call('EXISTS', KEYS[1] .. ':' .. KEYS[2] .. ':' .. ARGV[2] .. ':time') ~= 1 then
          -- time keeper does not exist
          -- update the ready sorted set with current time as ready time.
          redis.call('ZADD', KEYS[1] .. ':' .. KEYS[2], ARGV[1], ARGV[2])
       else
          -- time keeper exists
          local interval = ARGV[5]
          local last_dequeue_time = redis.call('GET', KEYS[1] .. ':' .. KEYS[2] .. ':' .. ARGV[2] .. ':time')
          local ready_time = interval + last_dequeue_time
          redis.call('ZADD', KEYS[1] .. ':' .. KEYS[2], ready_time, ARGV[2])
       end
    end

    -- update the metrics counters
    -- update global counter.
    local timestamp_minute = math.floor(ARGV[1]/60000) * 60000 -- get the epoch for the minute
    local expiry_time = math.floor((timestamp_minute + 600000) / 1000) -- store the data for 10 minutes.
    if redis.call('EXISTS', KEYS[1] .. ':enqueue_counter:' .. timestamp_minute) ~= 1 then
       -- counter does not exists. set the initial value and expiry.
       redis.call('SET', KEYS[1] .. ':enqueue_counter:' .. timestamp_minute, 1)
       redis.call('EXPIREAT', KEYS[1] .. ':enqueue_counter:' .. timestamp_minute, expiry_time)
    else
       -- counter already exists. just increment the value.
       redis.call('INCR', KEYS[1] .. ':enqueue_counter:' .. timestamp_minute)
    end

    -- update the current queue counter.
    if redis.call('EXISTS', KEYS[1] .. ':' .. KEYS[2] .. ':' .. ARGV[2] .. ':enqueue_counter:' .. timestamp_minute) ~= 1 then
       -- counter does not exists. set the initial value and expiry.
       redis.call('SET', KEYS[1] .. ':' .. KEYS[2] .. ':' .. ARGV[2] .. ':enqueue_counter:' .. timestamp_minute, 1)
       redis.call('EXPIREAT', KEYS[1] .. ':' .. KEYS[2] .. ':' .. ARGV[2] .. ':enqueue_counter:' .. timestamp_minute, expiry_time)
    else
       -- counter already exists. just increment the value.
       redis.call('INCR', KEYS[1] .. ':' .. KEYS[2] .. ':' .. ARGV[2] .. ':enqueue_counter:' .. timestamp_minute)
    end
  delete-mms.lua.lua: |

    -- script to mark a job as completed (finished) successfully.
    -- input:
    --     KEYS[1] - <key_prefix>
    --     KEYS[2] - <queue_type>
    --
    --     ARGV[1] - <queue_id>
    --     ARGV[2] - <job_id>
    -- output:
    --     nil
    -- remove the job from active sorted set.
    local response = redis.call('ZREM', KEYS[1] .. ':' .. KEYS[2] .. ':active', ARGV[1] .. ':' .. ARGV[2])
    if response ~= 1 then
       -- the job was not found in the active sorted set. Non existent job or
       -- the job is expired and was requeued back.
       return 0
    end
    -- check if the just-removed job was the last job in the active sorted set.
    if redis.call('EXISTS', KEYS[1] .. ':' .. KEYS[2] .. ':active') ~= 1 then
       -- yes. this was the last job. remove this queue_type
       -- from the metrics active queue type set.
       redis.call('SREM', KEYS[1] .. ':active:queue_type', KEYS[2])
    end
    -- delete the payload related to this job from the payload map.
    redis.call('HDEL', KEYS[1] .. ':payload', KEYS[2] .. ':' .. ARGV[1] .. ':' .. ARGV[2])
    if redis.call('EXISTS', KEYS[1] .. ':' .. KEYS[2] .. ':' .. ARGV[1]) ~= 1 then
       -- there are no more jobs in this queue. we can safely delete the interval.
       redis.call('HDEL', KEYS[1] .. ':interval', KEYS[2] .. ':' .. ARGV[1])
    end
    -- delete the requeues_remaining entry for this job.
    redis.call('HDEL', KEYS[1] .. ':' .. KEYS[2] .. ':' .. ARGV[1] .. ':requeues_remaining', ARGV[2])
    return 1
